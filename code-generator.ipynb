{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai langchain langgraph httpx langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJDlha7u8h7T",
        "outputId": "bfe3cdf2-d1d1-488b-d72c-54e42a79ed2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.1.5)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (1.0.7)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.16.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.11)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx) (0.14.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx) (1.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVjo_TgB7qYS"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, TypedDict, Optional\n",
        "from langgraph.graph import StateGraph, END\n",
        "import random\n",
        "import time\n",
        "\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# 1f. Import Google Colab library to access key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "def llm(x):\n",
        "    return model.invoke(x).content"
      ],
      "metadata": {
        "id": "i5Yi-x_-73wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphState(TypedDict):\n",
        "  feedback:Optional[str]\n",
        "  history: Optional[str]\n",
        "  code: Optional[str]\n",
        "  specialization: Optional[str]\n",
        "  rating: Optional[str]\n",
        "  iterations: Optional[int]\n",
        "  code_compare: Optional[str]\n",
        "  actual_code: Optional[str]\n",
        "  is_executable: Optional[str]\n",
        "\n",
        "workflow = StateGraph(GraphState)"
      ],
      "metadata": {
        "id": "SQB3y8Xq8rBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviewer_start= \"You are Code reviewer specialized in {}.\\\n",
        "You need to review the given code following PEP8 guidelines and potential bugs\\\n",
        "and point out issues as bullet list.\\\n",
        "Code:\\n {}\"\n",
        "\n",
        "coder_start = \"You are a Coder specialized in {}.\\\n",
        "Improve the given code given the following guidelines. Guideline:\\n {} \\n \\\n",
        "Code:\\n {} \\n \\\n",
        "Output just the improved code and nothing else.\"\n",
        "\n",
        "rating_start = \"Rate the skills of the coder on a scale of 10 given the Code review cycle with a short reason.\\\n",
        "Code review:\\n {} \\n \"\n",
        "\n",
        "code_comparison = \"Compare the two code snippets and rate on a scale of 10 to both. Dont output the codes.Revised Code: \\n {} \\n Actual Code: \\n {}\"\n",
        "\n",
        "classify_feedback = \"Are all feedback mentioned resolved in the code? Output just Yes or No.\\\n",
        "Code: \\n {} \\n Feedback: \\n {} \\n\"\n",
        "\n",
        "def handle_coder(state):\n",
        "    history = state.get('history', '').strip()\n",
        "    feedback = state.get('feedback', '').strip()\n",
        "    code =  state.get('code','').strip()\n",
        "    specialization = state.get('specialization','').strip()\n",
        "\n",
        "    print(\"CODER rewriting...\")\n",
        "\n",
        "    code = llm(coder_start.format(specialization,feedback,code))\n",
        "    return {'history':history+'\\n CODER:\\n'+code,'code':code}\n",
        "\n",
        "\n",
        "def handle_reviewer(state):\n",
        "    history = state.get('history', '').strip()\n",
        "    code = state.get('code', '').strip()\n",
        "    specialization = state.get('specialization','').strip()\n",
        "    iterations = state.get('iterations')\n",
        "\n",
        "    print(\"Reviewer working...\")\n",
        "\n",
        "    feedback = llm(reviewer_start.format(specialization,code))\n",
        "\n",
        "    return {'history':history+\"\\n REVIEWER:\\n\"+feedback,'feedback':feedback,'iterations':iterations+1}\n",
        "\n",
        "\n",
        "def handle_result(state):\n",
        "    print(\"Review done...\")\n",
        "\n",
        "    history = state.get('history', '').strip()\n",
        "    code1 = state.get('code', '').strip()\n",
        "    code2 = state.get('actual_code', '').strip()\n",
        "    rating  = llm(rating_start.format(history))\n",
        "\n",
        "    code_compare = llm(code_comparison.format(code1,code2))\n",
        "    return {'rating':rating,'code_compare':code_compare}"
      ],
      "metadata": {
        "id": "wym8Pjw5-O7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.add_node(\"handle_reviewer\",handle_reviewer)\n",
        "workflow.add_node(\"handle_coder\",handle_coder)\n",
        "workflow.add_node(\"handle_result\",handle_result)"
      ],
      "metadata": {
        "id": "TMf1XmOM_VgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deployment_ready(state):\n",
        "    deployment_ready = 1 if 'yes' in llm(classify_feedback.format(state.get('code'),state.get('feedback'))) else 0\n",
        "    total_iterations = 1 if state.get('iterations')>5 else 0\n",
        "    return \"handle_result\" if  deployment_ready or total_iterations else \"handle_coder\""
      ],
      "metadata": {
        "id": "bH1JwGf9_fQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.add_conditional_edges(\n",
        "    \"handle_reviewer\",\n",
        "    deployment_ready,\n",
        "    {\n",
        "        \"handle_result\": \"handle_result\",\n",
        "        \"handle_coder\": \"handle_coder\"\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.set_entry_point(\"handle_reviewer\")\n",
        "workflow.add_edge('handle_coder', \"handle_reviewer\")\n",
        "workflow.add_edge('handle_result', END)"
      ],
      "metadata": {
        "id": "fTaa9cy3Aazy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specialization = 'python'\n",
        "problem = 'Generate code to train a Regression ML model using a tabular dataset following required preprocessing steps.'\n",
        "code = llm(problem)\n",
        "\n",
        "app = workflow.compile()\n",
        "conversation = app.invoke({\"history\":code,\"code\":code,'actual_code':code,\"specialization\":specialization,'iterations':0},{\"recursion_limit\":100})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iANbzYQbAdVX",
        "outputId": "b14a1160-6c97-489d-f22f-43b69e92a02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviewer working...\n",
            "CODER rewriting...\n",
            "Reviewer working...\n",
            "CODER rewriting...\n",
            "Reviewer working...\n",
            "CODER rewriting...\n",
            "Reviewer working...\n",
            "CODER rewriting...\n",
            "Reviewer working...\n",
            "CODER rewriting...\n",
            "Reviewer working...\n",
            "Review done...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation['code'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kow6aUl_BbOQ",
        "outputId": "b0b975a2-645b-4749-f185-ba6d64765c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "import pandas as pd\n",
            "from sklearn.compose import ColumnTransformer\n",
            "from sklearn.linear_model import LinearRegression\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.pipeline import Pipeline\n",
            "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
            "\n",
            "# Load the tabular dataset\n",
            "try:\n",
            "    data = pd.read_csv('data.csv')\n",
            "except FileNotFoundError:\n",
            "    print(\"The file 'data.csv' was not found.\")\n",
            "    exit()\n",
            "\n",
            "# Check if the target_column column exists in the data\n",
            "if 'target_column' not in data.columns:\n",
            "    print(\"The 'target_column' column does not exist in the data.\")\n",
            "    exit()\n",
            "\n",
            "# Check if the categorical_columns and numerical_columns columns exist in the data\n",
            "categorical_columns = ['categorical_column_1', 'categorical_column_2']\n",
            "numerical_columns = list(set(data.columns) - set(categorical_columns))\n",
            "if not set(categorical_columns).issubset(data.columns) or not set(numerical_columns).issubset(data.columns):\n",
            "    print(\"The 'categorical_columns' or 'numerical_columns' columns do not exist in the data.\")\n",
            "    exit()\n",
            "\n",
            "# Preprocess the data\n",
            "preprocessor = ColumnTransformer(\n",
            "    transformers=[\n",
            "        ('num', StandardScaler(), numerical_columns),\n",
            "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
            "    ]\n",
            ")\n",
            "\n",
            "# Split the data into training and testing sets\n",
            "try:\n",
            "    x_train, x_test, y_train, y_test = train_test_split(data.drop('target_column', axis=1),\n",
            "                                                        data['target_column'],\n",
            "                                                        test_size=0.2,\n",
            "                                                        random_state=42)\n",
            "except ValueError:\n",
            "    print(\"The data could not be split into training and testing sets.\")\n",
            "    exit()\n",
            "\n",
            "# Train the regression model\n",
            "try:\n",
            "    model = Pipeline(steps=[('preprocessor', preprocessor),\n",
            "                            ('model', LinearRegression())])\n",
            "    model.fit(x_train, y_train)\n",
            "except ValueError:\n",
            "    print(\"The model could not be fit to the data.\")\n",
            "    exit()\n",
            "\n",
            "# Evaluate the model on the test set\n",
            "try:\n",
            "    score = model.score(x_test, y_test)\n",
            "    print(f'The score of the model on the test set is: {score}')\n",
            "except ValueError:\n",
            "    print(\"The model could not be scored on the data.\")\n",
            "    exit()\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation['actual_code'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ5oqMOsBoSp",
        "outputId": "bd5e6d35-856a-4aef-a4b3-d22eb3df128e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "import pandas as pd\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.linear_model import LinearRegression\n",
            "\n",
            "# Load the tabular dataset\n",
            "data = pd.read_csv('data.csv')\n",
            "\n",
            "# Preprocess the data\n",
            "# Handle missing values\n",
            "data = data.dropna()\n",
            "\n",
            "# Convert categorical variables to dummy variables\n",
            "data = pd.get_dummies(data, columns=['categorical_column_1', 'categorical_column_2'])\n",
            "\n",
            "# Split the data into training and testing sets\n",
            "X_train, X_test, y_train, y_test = train_test_split(data.drop(['target_column'], axis=1), \n",
            "                                                    data['target_column'], \n",
            "                                                    test_size=0.2, \n",
            "                                                    random_state=42)\n",
            "\n",
            "# Train the regression model\n",
            "model = LinearRegression()\n",
            "model.fit(X_train, y_train)\n",
            "\n",
            "# Evaluate the model on the test set\n",
            "score = model.score(X_test, y_test)\n",
            "print('The score of the model on the test set is:', score)\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation['code_compare'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH_J5yfjBxZI",
        "outputId": "30bc8fbd-8b8a-4889-f7b9-95288a689133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Revised Code: 9/10\n",
            "Actual Code: 7/10\n"
          ]
        }
      ]
    }
  ]
}